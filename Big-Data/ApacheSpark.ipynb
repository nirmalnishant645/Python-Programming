{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ApacheSpark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8qzwKUv91MN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-eu.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7KbT6F-n7XK",
        "colab_type": "code",
        "outputId": "9e20eb05-a79a-4d1d-a935-2083fc0df7bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "!pip install -q findspark\n",
        "!pip install py4j\n",
        "!pip install pyspark"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting py4j\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 21.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 40kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 51kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 71kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 81kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 92kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 102kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 112kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 122kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 133kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 143kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 153kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 163kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 174kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 184kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 194kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 9.5MB/s \n",
            "\u001b[?25hInstalling collected packages: py4j\n",
            "Successfully installed py4j-0.10.9\n",
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 62kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 53.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130388 sha256=4c547bef9b9820d8cc5c22688dd9402939547ef837c4aced48dc3885991fbead\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Found existing installation: py4j 0.10.9\n",
            "    Uninstalling py4j-0.10.9:\n",
            "      Successfully uninstalled py4j-0.10.9\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnYRY_-a91yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms_rPkLcmTbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "import findspark\n",
        "findspark.init(\"spark-2.4.4-bin-hadoop2.7\") #SPARK_HOME\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZP6QgiWYvZX",
        "colab_type": "code",
        "outputId": "855250e9-7c7d-42aa-9fcd-b73318ba6d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAqp8OTrbZBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tools we need to connect to the Spark server, load our data,\n",
        "# clean it and prepare itfrom pyspark import SparkContext\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import isnan, when, count, col# Set up constants\n",
        "\n",
        "CSV_2019= \"/content/gdrive/My Drive/Colab Notebooks/ApacheSpark/396352027_112019_597_airline_delay_causes.csv\"\n",
        "\n",
        "APP_NAME = \"Flight Delays\"\n",
        "SPARK_URL = \"local[*]\"\n",
        "\n",
        "RANDOM_SEED = 141109\n",
        "TRAINING_DATA_RATIO = 0.7\n",
        "RF_NUM_TREES = 8\n",
        "RF_MAX_DEPTH = 4\n",
        "RF_NUM_BINS = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUvn3JA6bs4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Connect to the Spark server\n",
        "\n",
        "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
        "\n",
        "# Load datasets\n",
        "\n",
        "df = spark.read.options(header=\"true\",inferschema = \"true\").csv(CSV_2019)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4ZojM0gb6_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5279247a-0948-471a-e30d-eebde99f70c3"
      },
      "source": [
        "print(f\"The shape is {df.count():d} rows by {len(df.columns):d} columns.\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape is 1762 rows by 22 columns.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HcBGFLccBIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "10139112-cb45-4cb7-cab0-085cf1ac4244"
      },
      "source": [
        "null_counts = df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c)for c in df.columns]).toPandas().to_dict(orient='records')\n",
        "print(f\"We have {sum(null_counts[0].values()):d} null values in this dataset.\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 1762 null values in this dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM-36rFZcd6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "51071bac-c73f-4939-b114-f386dc2d2f9f"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+------+-------+-----------------+-------+--------------------+-----------+---------+----------+-----------+------+-----------+----------------+-------------+------------+----------+--------------+-------------+---------+--------------+-------------------+----+\n",
            "|year| month|carrier|     carrier_name|airport|        airport_name|arr_flights|arr_del15|carrier_ct| weather_ct|nas_ct|security_ct|late_aircraft_ct|arr_cancelled|arr_diverted| arr_delay| carrier_delay|weather_delay|nas_delay|security_delay|late_aircraft_delay|_c21|\n",
            "+----+------+-------+-----------------+-------+--------------------+-----------+---------+----------+-----------+------+-----------+----------------+-------------+------------+----------+--------------+-------------+---------+--------------+-------------------+----+\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    ABE|Allentown/Bethleh...|       51.0|      3.0|       2.0|        0.0|   0.0|        0.0|             1.0|          0.0|         0.0|     127.0|          79.0|          0.0|      0.0|           0.0|               48.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    AEX|Alexandria, LA: A...|      106.0|     13.0|      6.56|       0.63|  2.32|        0.0|            3.48|          0.0|         0.0|     756.0|         419.0|         53.0|     85.0|           0.0|              199.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    AGS|Augusta, GA: Augu...|      135.0|     11.0|      6.02|        0.0|  3.04|        0.0|            1.94|          0.0|         0.0|     778.0|         565.0|          0.0|    119.0|           0.0|               94.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    ALB|Albany, NY: Alban...|       25.0|      2.0|      0.64|        0.0|   0.0|        0.0|            1.36|          1.0|         0.0|      59.0|          14.0|          0.0|      0.0|           0.0|               45.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    ATL|Atlanta, GA: Hart...|     3043.0|    311.0|     78.62|       7.03| 93.13|        0.0|          132.21|          0.0|         3.0|   21529.0|        8522.0|        487.0|   3304.0|           0.0|             9216.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    ATW|Appleton, WI: App...|       51.0|      7.0|      2.83|       0.13|  2.52|        0.0|            1.52|          0.0|         0.0|     286.0|         110.0|         14.0|     76.0|           0.0|               86.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    AUS|Austin, TX: Austi...|       36.0|      1.0|       0.0|        0.0|  0.37|        0.0|            0.63|          0.0|         0.0|      49.0|           0.0|          0.0|     18.0|           0.0|               31.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    AVL|Asheville, NC: As...|      157.0|     14.0|     10.86|       0.34|   2.6|        0.0|            0.19|          0.0|         1.0|     675.0|         599.0|         10.0|     61.0|           0.0|                5.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    BDL|Hartford, CT: Bra...|       52.0|      5.0|      0.54|        0.0|   0.6|        0.0|            3.87|          0.0|         0.0|     277.0|          17.0|          0.0|     54.0|           0.0|              206.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    BGR|Bangor, ME: Bango...|       82.0|      9.0|      3.29|        0.0|  1.51|        0.0|            4.19|          0.0|         0.0|     557.0|         229.0|          0.0|     47.0|           0.0|              281.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    BHM|Birmingham, AL: B...|       19.0|      4.0|       0.1|        0.0|  0.55|        0.0|            3.34|          0.0|         0.0|     245.0|           5.0|          0.0|     19.0|           0.0|              221.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    BIS|Bismarck/Mandan, ...|        1.0|      0.0|       0.0|        0.0|   0.0|        0.0|             0.0|          0.0|         0.0|       0.0|           0.0|          0.0|      0.0|           0.0|                0.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    BMI|Bloomington/Norma...|       77.0|      7.0|      1.21|        1.0|  2.17|        0.0|            2.62|          0.0|         0.0|     238.0|          45.0|         49.0|     47.0|           0.0|               97.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    BNA|Nashville, TN: Na...|       48.0|      6.0|       3.0|        0.0|  1.46|        0.0|            1.54|          0.0|         0.0|     361.0|         230.0|          0.0|     51.0|           0.0|               80.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    BOS|Boston, MA: Logan...|      296.0|     36.0|      6.37|       0.83| 18.28|        0.0|           10.51|          0.0|         1.0|    2050.0|         378.0|         25.0|    884.0|           0.0|              763.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    BTR|Baton Rouge, LA: ...|      196.0|     14.0|      7.15|        1.0|  0.57|        0.0|            5.28|          0.0|         0.0|     628.0|         360.0|         66.0|     11.0|           0.0|              191.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    BTV|Burlington, VT: B...|      218.0|     31.0|      5.08|       0.37| 10.73|        0.0|           14.82|          0.0|         2.0|    2196.0|         431.0|        117.0|    511.0|           0.0|             1137.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    BUF|Buffalo, NY: Buff...|      167.0|     19.0|      7.87|        0.0|   2.0|        0.0|            9.14|          1.0|         0.0|    1420.0|         847.0|          0.0|     58.0|           0.0|              515.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    BWI|Baltimore, MD: Ba...|      217.0|     17.0|       5.9|       0.09|  2.13|        0.0|            8.89|          0.0|         0.0|    1773.0|         856.0|         12.0|     69.0|           0.0|              836.0|null|\n",
            "|2019|    11|     9E|Endeavor Air Inc.|    CAE|Columbia, SC: Col...|       43.0|      7.0|      2.64|        0.0|  1.56|        0.0|             2.8|          0.0|         0.0|     333.0|         138.0|          0.0|     45.0|           0.0|              150.0|null|\n",
            "+----+------+-------+-----------------+-------+--------------------+-----------+---------+----------+-----------+------+-----------+----------------+-------------+------------+----------+--------------+-------------+---------+--------------+-------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J_5d9rkeXDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(df._c21)\n",
        "df = df.na.drop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvQX51kXeel8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a711320-8103-4126-e03c-d89c2c97aa18"
      },
      "source": [
        "print(f\"The shape is {df.count():d} rows by {len(df.columns):d} columns.\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape is 1762 rows by 21 columns.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAUadrreeh-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "d013bf76-46d2-4dc0-e5a7-31bf83c35898"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('year', 'int'),\n",
              " (' month', 'int'),\n",
              " ('carrier', 'string'),\n",
              " ('carrier_name', 'string'),\n",
              " ('airport', 'string'),\n",
              " ('airport_name', 'string'),\n",
              " ('arr_flights', 'double'),\n",
              " ('arr_del15', 'double'),\n",
              " ('carrier_ct', 'double'),\n",
              " (' weather_ct', 'double'),\n",
              " ('nas_ct', 'double'),\n",
              " ('security_ct', 'double'),\n",
              " ('late_aircraft_ct', 'double'),\n",
              " ('arr_cancelled', 'double'),\n",
              " ('arr_diverted', 'double'),\n",
              " (' arr_delay', 'double'),\n",
              " (' carrier_delay', 'double'),\n",
              " ('weather_delay', 'double'),\n",
              " ('nas_delay', 'double'),\n",
              " ('security_delay', 'double'),\n",
              " ('late_aircraft_delay', 'double')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoSn1wSwe7Wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import when   \n",
        "\n",
        "df = df.withColumn('arr_cancelled', when(df['arr_cancelled']>0,1).otherwise(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SfknmLCl20e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24482517-d907-4138-888c-39fabf2e0ed5"
      },
      "source": [
        "df.select('arr_cancelled').distinct().rdd.map(lambda r: r[0]).collect()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QAu4xf-l6P3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_cols = ['year', ' month', 'carrier_ct', ' weather_ct', 'nas_ct', 'security_ct', 'late_aircraft_ct']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2elyK8WfpEpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = VectorAssembler(inputCols=feature_cols, outputCol=\"features\").transform(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgx4iv6RrSDa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "9bd73d22-6039-451f-e1f1-1cbad2795709"
      },
      "source": [
        "df.select(\"arr_cancelled\", \"features\").show(5)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------+--------------------+\n",
            "|arr_cancelled|            features|\n",
            "+-------------+--------------------+\n",
            "|            0|[2019.0,11.0,2.0,...|\n",
            "|            0|[2019.0,11.0,6.56...|\n",
            "|            0|[2019.0,11.0,6.02...|\n",
            "|            1|[2019.0,11.0,0.64...|\n",
            "|            0|[2019.0,11.0,78.6...|\n",
            "+-------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZMUoKiKrWuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate a labelIndexer\n",
        "labelIndexer = StringIndexer(inputCol=\"arr_cancelled\", outputCol=\"indexedLabel\").fit(df)\n",
        "\n",
        "# Generate the indexed feature vector\n",
        "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(df)\n",
        "    \n",
        "# Split the data into training and tests sets\n",
        "(trainingData, testData) = df.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
        "\n",
        "# Train the RandomForest model\n",
        "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n",
        "\n",
        "# Chain indexers and the forest models in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bkXQ4tsrou2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model\n",
        "model = pipeline.fit(trainingData)# Make predictions\n",
        "predictions = model.transform(testData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POE9UDhArvqQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ede1cbc1-8cbd-47e2-9de6-d0723bec9854"
      },
      "source": [
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
        "print(f\"Accuracy = {accuracy:g}\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Error = 0.271375\n",
            "Accuracy = 0.728625\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
